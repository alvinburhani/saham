{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, sehingga kita dapat hasil yag sama setelah rerunning beberapa kali\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data dari Yahoo Finance database, apatah untuk scaling, shuffling, normalizing dan splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): nama kode Saham yang ingin diambil, examples include BRIS.JK, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) digunakan untuk prediksi, default = 50\n",
    "        scale (bool): apakah untuk merubah skala harga dari 0 ke 1, default = True\n",
    "        shuffle (bool): apakah mau mengacak dataset (baik training & testing), default = True\n",
    "        lookup_step (int): langkah untuk melihat ke depan dalam prediksi, defaultnya 1 (misal 1 hari besok)\n",
    "        split_by_date (bool): apakah dataset mau dipisah antara training/testing by date, silahkan set disini \n",
    "            ke False maka datasets akan displit secara random\n",
    "        test_size (float): rasio uji data, default nilainya 0.2 (20% testing data)\n",
    "        feature_columns (list): List features yang digunakan dalam model, defaultnya apasaja yang ada dari yahoo_fin\n",
    "    \"\"\"\n",
    "    # Cek apakah Kode Tiker sudah diambil dari yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load dari yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # Sudah loaded, langsung kita gunakan\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    \n",
    "    # disini akan berisi semua yang ingin tampilkan dari fungsi-fungsi disini\n",
    "    result = {}\n",
    "    \n",
    "    # kita juga tampilkan original dataframe itu sendiri\n",
    "    result['df'] = df.copy()\n",
    "    \n",
    "    # pastikan passed feature_columns ada dalam dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' gak ada dalam dataframe.\"\n",
    "    \n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        \n",
    "        # scale data (harga) dari 0 ke 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        \n",
    "        # tambahkan contoh MinMaxScaler dalam tampilan\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    \n",
    "    # tambah column (label) dari `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    \n",
    "    # last `lookup_step` columns yang kosong atau NaN in dalam kolom future\n",
    "    # Rekam dulu sebelum NaNs dibuang\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    \n",
    "    # Buang data NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    \n",
    "    # Ambil last sequence dengan menambah last `n_step` sequence dengan `lookup_step` sequence\n",
    "    # Misalnya, jika n_steps=50 dan lookup_step=10, maka last_sequence seharusnya 60 (dimana 50+10) untuk panjangnya\n",
    "    # Data last_sequence akan digunakan untuk predict harga saham kedepan yang tidak ada dalam datasets\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    \n",
    "    # Tambahkan Result-nya\n",
    "    result['last_sequence'] = last_sequence\n",
    "    \n",
    "    # Buat X's dan y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    # convert ke numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split dataset jadi training & testing berdasarkan tanggal (bukan splitting secara random)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle datasets untuk data training (jika shuffle parameter adalah set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split dataset secara random\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # list data test berdasarkan tanggal\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    \n",
    "    # tampilkan test features dari original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    \n",
    "    # buang tanggal yang sama pada testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    \n",
    "    # buang tanggal dari training/testing sets & convert ke float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # tambah dropout pada setiap layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Ukuran Window untui panjang sequensinya\n",
    "N_STEPS = 50\n",
    "\n",
    "# Lookup step, 1 adalah sehari yang akan datang\n",
    "LOOKUP_STEP = 15\n",
    "\n",
    "# Apakah mau scale feature columns & output harganya\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "\n",
    "# Apakah mau shuffle dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "\n",
    "# Apakah mau pisahin training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "\n",
    "# Ukuran test ratio, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# features yang akan digunakan\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "# tanggal sekarang\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "\n",
    "# Apakah mau menggunakan metode bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 18\n",
    "\n",
    "# Kode Harga Saham dari Yahoo Fiance\n",
    "ticker = \"BRIS.JK\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "\n",
    "# model disimpan, nama dibuat seunik mungkin berdasarkan parameternya\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat folders jika belom ada\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# Simpan dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "\n",
    "# Buat modelnya\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "# Tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "\n",
    "# train model dan simpan bobotnya dimanapun kita lihat \n",
    "# Sebuah model optimal baru dalam ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Gunakan Prompt atau Power Shell dan ketikan perintah ini:\n",
    "tensorboard --logdir=\"logs\"\n",
    "\n",
    "#Masuk ke Web\n",
    "http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    Fungsi ini akan menggambarkan harga penutupan bersama dengan harga yang diprediksi kedepan\n",
    "    dengan masing-masing warna biru dan merah\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Hari Perdangan Saham\")\n",
    "    plt.ylabel(\"Harga Penutupan\")\n",
    "    plt.legend([\"Harga Saham\", \"Harga Prediksi\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    Fungsi ini mengambil dict 'model' dan 'data' untuk \n",
    "    membangun kerangka akhir dataframe dimana sudah mencakup fitur-fitur di sepanjang \n",
    "    harga aktual dan harga prediksi dari kumpulan data pengujian\n",
    "    \"\"\"\n",
    "    # jika harga prediksi lebih tinggi dari harga sekarang, \n",
    "    # maka hitung harga kedepan dikurangi dengan harga sekarang guna mendapatkan nilai untung\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    \n",
    "    # jika harga prediksi lebih renda dari harga sekarang,\n",
    "    # maka kurangi harga yang akan datang dengan hargasebenarnya pada harga saat ini\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    \n",
    "    # Tampilkan prediksi dan dapatkan harganya\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    \n",
    "    # Tambahkan harga prediksi kedepan dalam dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    \n",
    "    # Tambahkan harga aktual kedepan dalam dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    \n",
    "    # sort dataframe berdasarkan tanggal\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    \n",
    "    # Tambah kolom keuntungan beli\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # Tambah kolom keuntungan jual\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # Tarik last sequence dari data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    \n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    \n",
    "    # Penskalaan prediksi (dari 0 ke 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "   \n",
    "    # Harga Prediksi (setelah skala diinvert)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Handling Error saja...\n",
    "except HTMLParseError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Muat optimal model weights dari results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluasi  model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "\n",
    "# Hitung mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe dari data pengujian\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi harga kedepan\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kita hitung accurasinya dengan menghitung jumlah positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "\n",
    "# perhitungan total beli & profit penjualan\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "\n",
    "# total profit dengan menambah penualan dan pembelian secara bersama\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "\n",
    "# pembagian total profit dengan jumlah testing samples (jumlah penjualan)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing metrics\n",
    "print(f\"Harga yang akan datang setelah {LOOKUP_STEP} hari adalah sebesar {future_price:.2f} Rupiah\")\n",
    "print(f\"{LOSS} rugi:\", loss)\n",
    "print(\"Mean Absolute Error MAE:\", mean_absolute_error)\n",
    "print(\"Accuracy Score:\", accuracy_score)\n",
    "print(\"Total keuntungan pembelian:\", total_buy_profit)\n",
    "print(\"Total keuntungan penjualan:\", total_sell_profit)\n",
    "print(\"Total profit keuntungan:\", total_profit)\n",
    "print(\"Profit per penjualan:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot grafik harga aktual dan harga prediksi\n",
    "plt.figure(figsize=(16, 10)) \n",
    "plt.style.use('ggplot')\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10)) \n",
    "plt.style.use('seaborn')\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.tail(10))\n",
    "# Simpan final dataframe ke folder hasil dalam format csv\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
